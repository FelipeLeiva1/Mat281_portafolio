{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MAT281 - Laboratorio N°08\n"},{"metadata":{},"cell_type":"markdown","source":"<a id='p1'></a>\n## I.- Problema 01\n\n\n<img src=\"https://www.cardrates.com/wp-content/uploads/2020/08/shutterstock_576998230.jpg?1\" width=\"480\" height=\"360\" align=\"center\"/>\n\n\nEl conjunto de datos se denomina `creditcard.csv` y consta de varias columnas con información acerca del fraude de tarjetas de crédito, en donde la columna **Class** corresponde a: 0 si no es un fraude y 1 si es un fraude.\n\nEn este ejercicio se trabajará el problemas de  clases desbalancedas. Veamos las primeras cinco filas dle conjunto de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n%matplotlib inline\nsns.set_palette(\"deep\", desat=.6)\nsns.set(rc={'figure.figsize':(11.7,8.27)})","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cargar datos\ndf = pd.read_csv(os.path.join(\"data\",\"creditcard.csv\"), sep=\";\")\ndf.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n2  10.0  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230 -0.689405   \n3  10.0  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027  0.470455   \n4  12.0  1.103215 -0.040296  1.267332  1.289091 -0.735997  0.288069 -0.586057   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n2 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668  0.392831  0.161135   \n3  0.538247 -0.558895  ...  0.049924  0.238422  0.009130  0.996710 -0.767315   \n4  0.189380  0.782333  ... -0.024612  0.196002  0.013802  0.103758  0.364298   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1 -0.257237  0.034507  0.005168    4.99      0  \n2 -0.354990  0.026416  0.042422  121.50      0  \n3 -0.492208  0.042472 -0.054337    9.99      0  \n4 -0.382261  0.092809  0.037051   12.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.0</td>\n      <td>1.229658</td>\n      <td>0.141004</td>\n      <td>0.045371</td>\n      <td>1.202613</td>\n      <td>0.191881</td>\n      <td>0.272708</td>\n      <td>-0.005159</td>\n      <td>0.081213</td>\n      <td>0.464960</td>\n      <td>...</td>\n      <td>-0.167716</td>\n      <td>-0.270710</td>\n      <td>-0.154104</td>\n      <td>-0.780055</td>\n      <td>0.750137</td>\n      <td>-0.257237</td>\n      <td>0.034507</td>\n      <td>0.005168</td>\n      <td>4.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.0</td>\n      <td>1.249999</td>\n      <td>-1.221637</td>\n      <td>0.383930</td>\n      <td>-1.234899</td>\n      <td>-1.485419</td>\n      <td>-0.753230</td>\n      <td>-0.689405</td>\n      <td>-0.227487</td>\n      <td>-2.094011</td>\n      <td>...</td>\n      <td>-0.231809</td>\n      <td>-0.483285</td>\n      <td>0.084668</td>\n      <td>0.392831</td>\n      <td>0.161135</td>\n      <td>-0.354990</td>\n      <td>0.026416</td>\n      <td>0.042422</td>\n      <td>121.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.0</td>\n      <td>0.384978</td>\n      <td>0.616109</td>\n      <td>-0.874300</td>\n      <td>-0.094019</td>\n      <td>2.924584</td>\n      <td>3.317027</td>\n      <td>0.470455</td>\n      <td>0.538247</td>\n      <td>-0.558895</td>\n      <td>...</td>\n      <td>0.049924</td>\n      <td>0.238422</td>\n      <td>0.009130</td>\n      <td>0.996710</td>\n      <td>-0.767315</td>\n      <td>-0.492208</td>\n      <td>0.042472</td>\n      <td>-0.054337</td>\n      <td>9.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.0</td>\n      <td>1.103215</td>\n      <td>-0.040296</td>\n      <td>1.267332</td>\n      <td>1.289091</td>\n      <td>-0.735997</td>\n      <td>0.288069</td>\n      <td>-0.586057</td>\n      <td>0.189380</td>\n      <td>0.782333</td>\n      <td>...</td>\n      <td>-0.024612</td>\n      <td>0.196002</td>\n      <td>0.013802</td>\n      <td>0.103758</td>\n      <td>0.364298</td>\n      <td>-0.382261</td>\n      <td>0.092809</td>\n      <td>0.037051</td>\n      <td>12.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Analicemos el total de fraudes respecto a los casos que nos son fraudes:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calcular proporciones\ndf_count = pd.DataFrame()\ndf_count[\"fraude\"] =[\"no\",\"si\"]\ndf_count[\"total\"] = df[\"Class\"].value_counts() \ndf_count[\"porcentaje\"] = 100*df_count[\"total\"] /df_count[\"total\"] .sum()\n\ndf_count","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  fraude  total  porcentaje\n0     no  50000   99.025588\n1     si    492    0.974412","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fraude</th>\n      <th>total</th>\n      <th>porcentaje</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>no</td>\n      <td>50000</td>\n      <td>99.025588</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>si</td>\n      <td>492</td>\n      <td>0.974412</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Se observa que menos del 1% corresponde a registros frudulentos. La pregunta que surgen son:\n\n* ¿ Cómo deben ser el conjunto de entrenamiento y de testeo?\n* ¿ Qué modelos ocupar?\n* ¿ Qué métricas ocupar?\n\nPor ejemplo, analicemos el modelos de regresión logística y apliquemos el procedimiento estándar:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# datos \ny = df.Class\nX = df.drop('Class', axis=1)\n\n# split dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n\n\n# Creando el modelo\nlr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n \n# predecir\nlr_pred = lr.predict(X_test)\n\n# calcular accuracy\naccuracy_score(y_test, lr_pred)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"0.9961181969420898"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"En general el modelo tiene un **accuracy** del 99,9%, es decir, un podría suponer que el modelo predice casi perfectamente, pero eso esta lejos de ser así.  Para ver por qué es necesario seguir los siguientes pasos:"},{"metadata":{},"cell_type":"markdown","source":"### 1. Cambiar la métrica de rendimiento\n\nEl primer paso es comparar con distintas métricas, para eso ocupemos las 4 métricas clásicas abordadas en el curso:\n* accuracy\n* precision\n* recall\n* f-score\n\nEn este punto deberá poner las métricas correspondientes y comentar sus resultados."},{"metadata":{"trusted":true},"cell_type":"code","source":"# metrics\ny_true =  list(y_test)\ny_pred = list(lr.predict(X_test))\n\nprint('\\nMatriz de confusion:\\n ')\nprint(confusion_matrix(y_true,y_pred))\n\nprint('\\nMetricas:\\n ')\nprint('accuracy:   ',accuracy_score(y_test, lr_pred))\nprint('recall:     ',recall_score(y_test, lr_pred))\nprint('precision:  ',precision_score(y_test, lr_pred))\nprint('f-score:    ',f1_score(y_test, lr_pred))\nprint(\"\")","execution_count":5,"outputs":[{"output_type":"stream","text":"\nMatriz de confusion:\n \n[[12471    16]\n [   33   103]]\n\nMetricas:\n \naccuracy:    0.9961181969420898\nrecall:      0.7573529411764706\nprecision:   0.865546218487395\nf-score:     0.807843137254902\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"\nTenemos que al tener clases desbalanceadas el modelo predice muy bien los verdaderos positivos pero en mucha menor cantidad los verdaderos negativos. Esto produce un accuracy muy elevado y las otras métricas, si bien no son malas, puede darnos indicios de que que quizas debemos abordar el problema con otros métodos para evitar predicciones incorrectas"},{"metadata":{},"cell_type":"markdown","source":"### 2. Cambiar algoritmo\n\nEl segundo paso es comparar con distintos modelos. Debe tener en cuenta que el modelo ocupaod resuelva el problema supervisado de clasificación.\n\nEn este punto deberá ajustar un modelo de **random forest**, aplicar las métricas y comparar con el modelo de regresión logística."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n# train model\n\nrfc =  RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1) # algoritmo random forest\n\nX, y = make_classification(n_features=30, n_redundant=0, n_informative=2,\n                           random_state=1, n_clusters_per_class=1)\n\nrfc.fit(X, y)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metrics\n\ny_true =  list(y_test)\ny_pred = list(rfc.predict(X_test)) # predicciones con random forest\n\n\nprint('\\nMatriz de confusion:\\n ')\nprint(confusion_matrix(y_true,y_pred))\n\nprint('\\nMetricas:\\n ')\nprint('accuracy:   ',accuracy_score(y_true,y_pred))\nprint('recall:     ',recall_score(y_true,y_pred))\nprint('precision:  ',precision_score(y_true,y_pred))\nprint('f-score:    ',f1_score(y_true,y_pred))\nprint(\"\")","execution_count":7,"outputs":[{"output_type":"stream","text":"\nMatriz de confusion:\n \n[[8663 3824]\n [ 107   29]]\n\nMetricas:\n \naccuracy:    0.6885843301909214\nrecall:      0.21323529411764705\nprecision:   0.007526602647287828\nf-score:     0.01453998495863625\n\n","name":"stdout"},{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"A través de las métricas y la matriz de confusión, nos damos cuenta de que este modelo no para nada efectivo para esta instancia, pues aumentaron drásticamente los Falsos positivos y las predicciones de la diagonal bajaron considerablemente"},{"metadata":{},"cell_type":"markdown","source":"### 3. Técnicas de remuestreo: sobremuestreo de clase minoritaria\n\nEl tercer paso es ocupar ténicas de remuestreo, pero sobre la clase minoritaria. Esto significa que mediantes ténicas de remuestreo trataremos de equiparar el número de elementos de la clase minoritaria a la clase mayoritaria."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n\n# concatenar el conjunto de entrenamiento\nX = pd.concat([X_train, y_train], axis=1)\n\n# separar las clases\nnot_fraud = X[X.Class==0]\nfraud = X[X.Class==1]\n\n# remuestrear  clase minoritaria\nfraud_upsampled = resample(fraud,\n                          replace=True, # sample with replacement\n                          n_samples=len(not_fraud), # match number in majority class\n                          random_state=27) # reproducible results\n\n# recombinar resultados\nupsampled = pd.concat([not_fraud, fraud_upsampled])\n\n# chequear el número de elementos por clases\nupsampled.Class.value_counts()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"0    37513\n1    37513\nName: Class, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# datos de entrenamiento sobre-balanceados\ny_train = upsampled.Class\nX_train = upsampled.drop('Class', axis=1)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ocupando estos nuevos conjunto de entrenamientos, vuelva a aplicar el modelos de regresión logística y calcule las correspondientes métricas. Además, justifique las ventajas y desventjas de este procedimiento."},{"metadata":{"trusted":true},"cell_type":"code","source":"upsampled = LogisticRegression() # algoritmo de regresion logistica\n\nupsampled.fit(X_train, y_train)\n\n# metrics\n\ny_true =  list(y_test)\ny_pred = list(upsampled.predict(X_test))\n\n\nprint('\\nMatriz de confusion:\\n ')\nprint(confusion_matrix(y_true,y_pred))\n\nprint('\\nMetricas:\\n ')\nprint('accuracy:   ',accuracy_score(y_true,y_pred))\nprint('recall:     ',recall_score(y_true,y_pred))\nprint('precision:  ',precision_score(y_true,y_pred))\nprint('f-score:    ',f1_score(y_true,y_pred))\nprint(\"\")","execution_count":10,"outputs":[{"output_type":"stream","text":"\nMatriz de confusion:\n \n[[12102   385]\n [   10   126]]\n\nMetricas:\n \naccuracy:    0.9687079141250099\nrecall:      0.9264705882352942\nprecision:   0.2465753424657534\nf-score:     0.3894899536321484\n\n","name":"stdout"},{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"\nNotemos que los aciertos de verdaderos positivos disminuye levemente, aumentando los aciertos en los Verdaderos negativos, sin embargo se ve un aumento considerable en la cantidad de Falsos positivos"},{"metadata":{},"cell_type":"markdown","source":"### 4. Técnicas de remuestreo - Ejemplo de clase mayoritaria\n\nEl cuarto paso es ocupar ténicas de remuestreo, pero sobre la clase mayoritaria. Esto significa que mediantes ténicas de remuestreo trataremos de equiparar el número de elementos de la clase mayoritaria  a la clase minoritaria."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remuestreo clase mayoritaria\nnot_fraud_downsampled = resample(not_fraud,\n                                replace = False, # sample without replacement\n                                n_samples = len(fraud), # match minority n\n                                random_state = 27) # reproducible results\n\n# recombinar resultados\ndownsampled = pd.concat([not_fraud_downsampled, fraud])\n\n# chequear el número de elementos por clases\ndownsampled.Class.value_counts()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"0    356\n1    356\nName: Class, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# datos de entrenamiento sub-balanceados\n\ny_train = downsampled.Class\nX_train = downsampled.drop('Class', axis=1)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ocupando estos nuevos conjunto de entrenamientos, vuelva a aplicar el modelos de regresión logística y calcule las correspondientes métricas. Además, justifique las ventajas y desventjas de este procedimiento."},{"metadata":{"trusted":true},"cell_type":"code","source":"undersampled = LogisticRegression() # modelo de regresi+on logística\n\nundersampled.fit(X_train, y_train)\n# metrics\n\ny_true =  list(y_test)\ny_pred = list(undersampled.predict(X_test))\n\n\nprint('\\nMatriz de confusion:\\n ')\nprint(confusion_matrix(y_true,y_pred))\n\nprint('\\nMetricas:\\n ')\nprint('accuracy:   ',accuracy_score(y_true,y_pred))\nprint('recall:     ',recall_score(y_true,y_pred))\nprint('precision:  ',precision_score(y_true,y_pred))\nprint('f-score:    ',f1_score(y_true,y_pred))\nprint(\"\")","execution_count":13,"outputs":[{"output_type":"stream","text":"\nMatriz de confusion:\n \n[[11862   625]\n [   10   126]]\n\nMetricas:\n \naccuracy:    0.9496950011883071\nrecall:      0.9264705882352942\nprecision:   0.1677762982689747\nf-score:     0.28410372040586246\n\n","name":"stdout"},{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"\nAnaloga a la explicación anterior, sin embargo en este caso, se ve un aumento aun mas considerable en los Falsos positivos."},{"metadata":{},"cell_type":"markdown","source":"### 5. Conclusiones\n\nPara finalizar el laboratorio, debe realizar un análisis comparativo con los disintos resultados obtenidos  en los pasos 1-4. Saque sus propias conclusiones del caso."},{"metadata":{},"cell_type":"markdown","source":"Como conclusión se puede extraer que dependiendo de la situación en la que nos encontremos, será conveniente utilizar distintas técnicas de muestreo. Esto dependerá de qué es lo que más se valore en distintas situaciones, por ejemplo si nos interesa tener una mayor cantidad de aciertos de verdaderos positivos, es conveniente utilizar Regresión Logística como en el caso 1. Sin embargo, si nuestro interés está en aumentar la candidad de aciertos de verdaderos negativos, puede ser recomendable utilizar técnicas de muestre como en 3 y 4. Para efectos de este ejemplo, no es recomendable utilizar Random-Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}